# documentation for actions
# https://docs.github.com/en/actions/creating-actions/metadata-syntax-for-github-actions#inputs

name: 'hasura-database-backup'
description: 'Backup a Hasura database'

inputs:
  AWS_S3_BUCKET_NAME:
    description: 'upload destination, e.g. magic.iamnoah.com'
    required: true
  AWS_S3_BUCKET_DIR:
    description: 'directory within bucket, e.g. hasura-database-backup'
    required: false
    default: 'hasura-database-backup'
  HASURA_HOST:
    description: 'full graphql hostname, e.g. https://magic-graphql.iamnoah.com'
    required: true


  # secrets defined in github settings
  # used for curls for schema + metadata
  HASURA_ADMIN_SECRET:
    required: true

  # used for ssh pg_dump
  MAGIC_AUTH_DATABASE_URL:
    required: true
  MAGIC_AUTH_SSH_HOST:
    required: true
  MAGIC_AUTH_SSH_USER:
    required: true
  MAGIC_AUTH_SSH_PRIVATE_KEY:
    required: true

  # sync files to s3 bucket
  AWS_ACCESS_KEY_ID:
    required: true
  AWS_SECRET_ACCESS_KEY:
    required: true

runs:
  using: "composite"
  steps:
    - name: backup database to sql files
      run: ${{ github.action_path }}/backup.sh
      shell: bash
      env:
        AWS_S3_BUCKET_DIR: ${{ inputs.AWS_S3_BUCKET_DIR }}
        HASURA_HOST: ${{ inputs.HASURA_HOST }}
        HASURA_ADMIN_SECRET: ${{ inputs.HASURA_ADMIN_SECRET }}

    - name: execute pg_dump for data.sql over ssh
      uses: appleboy/ssh-action@v0.1.8
      with:
        host: ${{ inputs.MAGIC_AUTH_SSH_HOST }}
        username: ${{ inputs.MAGIC_AUTH_SSH_USER }}
        key: ${{ inputs.MAGIC_AUTH_SSH_PRIVATE_KEY }}
        script: |
          dokku run hasura pg_dump ${{ inputs.MAGIC_AUTH_DATABASE_URL}} --no-owner --no-acl --data-only --schema public > data.sql
          ls -lsah

    - name: download data.sql over scp
      uses: nicklasfrahm/scp-action@main
      with:
        direction: download
        insecure_ignore_fingerprint: true
        host: ${{ inputs.MAGIC_AUTH_SSH_HOST }}
        username: ${{ inputs.MAGIC_AUTH_SSH_USER }}
        key: ${{ inputs.MAGIC_AUTH_SSH_PRIVATE_KEY }}
        source: data.sql
        target: data.sql

    - name: move local copy of data.sql after scp into aws bucket dir
      shell: bash
      run: |
        ls -lsah
        mv data.sql ${{ inputs.AWS_S3_BUCKET_DIR }}

    - name: sync to S3 bucket
      uses: jakejarvis/s3-sync-action@v0.5.1
      with:
        args: --delete
      env:
        # authentication
        AWS_ACCESS_KEY_ID: ${{ inputs.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ inputs.AWS_SECRET_ACCESS_KEY }}
        # bucket location
        AWS_REGION: 'us-west-1'
        AWS_S3_BUCKET: ${{ inputs.AWS_S3_BUCKET_NAME }}

        # upload the env.AWS_S3_BUCKET_NAME where we output the backup above
        # optional: defaults to entire repository
        SOURCE_DIR: '${{ inputs.AWS_S3_BUCKET_DIR }}'

        # directory (key) to upload to inside of s3 bucket
        # remember s3 doesn't really have folders, this is just prepending to filename key
        # e.g. path/to/file is really just `path-to-file`
        DEST_DIR: '${{ inputs.AWS_S3_BUCKET_DIR }}'
